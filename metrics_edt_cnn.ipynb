{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encoder and PCA comparison using Little House Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "\n",
    "from keras.layers import Dense, Flatten, Reshape, Input, InputLayer, Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from scipy import interpolate\n",
    "\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroidnp(arr):\n",
    "    length = arr.shape[0]\n",
    "    sum_x = np.sum(arr[:, 0])\n",
    "    sum_y = np.sum(arr[:, 1])\n",
    "    return sum_x/length, sum_y/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hull_interpolation(x_hull, y_hull):\n",
    "    dist = np.sqrt((x_hull[:-1] - x_hull[1:])**2 + (y_hull[:-1] - y_hull[1:])**2)\n",
    "    dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "    spline, u = interpolate.splprep([x_hull, y_hull], \n",
    "                                    u=dist_along, s=0, per=1)\n",
    "    interp_d = np.linspace(dist_along[0], dist_along[-1], 50)\n",
    "    interp_x, interp_y = interpolate.splev(interp_d, spline)\n",
    "    return [interp_x, interp_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3clusters(X, y, title, vtitle, target_names):\n",
    "    plt.figure()\n",
    "    colors = ['r', 'g', 'k', 'b']\n",
    "    lw = 2\n",
    "\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2, 3], target_names):\n",
    "        plt.scatter(X[y == i, 0], X[y == i, 1], color=color, alpha=1., lw=lw, label=target_name)\n",
    "        points = np.take(X[y == i], [0,1], 1)\n",
    "        cent = centroidnp(points)\n",
    "        plt.plot(cent[0], cent[1], alpha=0.95, c=color, marker='D')\n",
    "        for n in range(0,points.shape[0]):\n",
    "            x_point = [points[n, 0], cent[0]]\n",
    "            y_point = [points[n, 1], cent[1]]\n",
    "            plt.plot(x_point, y_point, alpha=0.4, c=color)\n",
    "    \n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title(title)  \n",
    "    plt.xlabel(vtitle + \"1\")\n",
    "    plt.ylabel(vtitle + \"2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot4clusters(X, y, title, vtitle, target_names):\n",
    "    plt.figure()\n",
    "    colors = ['r', 'g', 'c', 'k', 'b']\n",
    "    # colors = ['k', 'k', 'k', 'k', 'k']\n",
    "    lw = 2\n",
    "\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2, 3, 4], target_names):\n",
    "        plt.scatter(X[y == i, 0], X[y == i, 1], color=color, alpha=1., lw=lw, label=target_name)\n",
    "        points = np.take(X[y == i], [0,1], 1)\n",
    "        cent = centroidnp(points)\n",
    "        plt.plot(cent[0], cent[1], alpha=0.95, c=color, marker='D')\n",
    "        for n in range(0,points.shape[0]):\n",
    "            x_point = [points[n, 0], cent[0]]\n",
    "            y_point = [points[n, 1], cent[1]]\n",
    "            plt.plot(x_point, y_point, alpha=0.4, c=color)\n",
    "    \n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title(title)  \n",
    "    plt.xlabel(vtitle + \"1\")\n",
    "    plt.ylabel(vtitle + \"2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot5clusters(X, y, title, vtitle, target_names):\n",
    "    plt.figure()\n",
    "    colors = ['r', 'g', 'k', 'c', 'y', 'b']\n",
    "    # colors = ['k', 'k', 'k', 'k', 'k', 'k']\n",
    "    lw = 2\n",
    "\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2, 3, 4, 5], target_names):\n",
    "        plt.scatter(X[y == i, 0], X[y == i, 1], color=color, alpha=1., lw=lw, label=target_name)\n",
    "        points = np.take(X[y == i], [0,1], 1)\n",
    "        cent = centroidnp(points)\n",
    "        plt.plot(cent[0], cent[1], alpha=0.95, c=color, marker='D')\n",
    "        for n in range(0,points.shape[0]):\n",
    "            x_point = [points[n, 0], cent[0]]\n",
    "            y_point = [points[n, 1], cent[1]]\n",
    "            plt.plot(x_point, y_point, alpha=0.4, c=color)\n",
    "    \n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title(title)  \n",
    "    plt.xlabel(vtitle + \"1\")\n",
    "    plt.ylabel(vtitle + \"2\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.load('edt_statistics.npy')\n",
    "stats = stats.reshape(53,500,500)\n",
    "num_files = np.shape(stats)[0]\n",
    "stats = stats.reshape(num_files,-1)\n",
    "\n",
    "stats_scaled = StandardScaler().fit_transform(stats)\n",
    "stats_scaled = stats_scaled.reshape(53,500,500,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sample = np.zeros((num_files))\n",
    "label_bld_plt = np.zeros((num_files))\n",
    "\n",
    "label_sample[0:5] = 0\n",
    "label_sample[16:19] = 0\n",
    "label_sample[38:43] = 0\n",
    "label_sample[5:10] = 1\n",
    "label_sample[28:33] = 1\n",
    "label_sample[43:48] = 1\n",
    "label_sample[33:38] = 2\n",
    "label_sample[10:15] = 2\n",
    "label_sample[48:53] = 2\n",
    "label_sample[19:24] = 3\n",
    "label_sample[24:28] = 4\n",
    "label_sample[15:16] = 5\n",
    "\n",
    "label_bld_plt[0:15] = 0\n",
    "label_bld_plt[16:19] = 1\n",
    "label_bld_plt[19:28] = 2\n",
    "label_bld_plt[28:38] = 1\n",
    "label_bld_plt[38:53] = 2\n",
    "label_bld_plt[15:16] = 3\n",
    "\n",
    "sample_name = ['Sample 11', 'Sample 6', 'Sample 7', 'Sample 13', 'Sample 1', ' ']\n",
    "bld_plt_name = ['NP220302-1', 'NP220322-2', 'NP220404-1', ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linear_autoencoder(inp_shape, code_size):\n",
    "    # The encoder\n",
    "    encoder = Sequential()\n",
    "    encoder.add(InputLayer(inp_shape))\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(code_size, activation='linear', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "    # The decoder\n",
    "    decoder = Sequential()\n",
    "    decoder.add(InputLayer((code_size)))\n",
    "    decoder.add(Dense(np.prod(inp_shape), activation='linear', kernel_initializer='glorot_uniform')) \n",
    "    decoder.add(Reshape(inp_shape))\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sigmoid_autoencoder(inp_shape, code_size):\n",
    "    # The encoder\n",
    "    encoder = Sequential()\n",
    "    encoder.add(InputLayer(inp_shape))\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(code_size, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "    # The decoder\n",
    "    decoder = Sequential()\n",
    "    decoder.add(InputLayer((code_size)))\n",
    "    decoder.add(Dense(np.prod(inp_shape), activation='sigmoid', kernel_initializer='glorot_uniform')) \n",
    "    decoder.add(Reshape(inp_shape))\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_relu_autoencoder(inp_shape, code_size):\n",
    "    # The encoder\n",
    "    encoder = Sequential()\n",
    "    encoder.add(InputLayer(inp_shape))\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(code_size, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "    # The decoder\n",
    "    decoder = Sequential()\n",
    "    decoder.add(InputLayer((code_size)))\n",
    "    decoder.add(Dense(np.prod(inp_shape), activation='sigmoid', kernel_initializer='glorot_uniform')) \n",
    "    decoder.add(Reshape(inp_shape))\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_var_autoencoder(inp_shape, code_size):\n",
    "    # The encoder\n",
    "    encoder = Sequential()\n",
    "    encoder.add(InputLayer(inp_shape))\n",
    "    encoder.add(Conv2D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
    "    encoder.add(Conv2D(filters=64, kernel_size=3, strides=2, activation='relu'))\n",
    "    encoder.add(Conv2D(filters=128, kernel_size=3, strides=2, activation='relu'))\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(code_size))#, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "    # The decoder\n",
    "    decoder = Sequential()\n",
    "    decoder.add(InputLayer((code_size,)))\n",
    "    # decoder.add(Dense(np.prod(inp_shape), activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "    decoder.add(Dense(np.prod(inp_shape), activation='relu'))#, kernel_initializer='glorot_uniform')) \n",
    "    decoder.add(Reshape(target_shape=(500, 500, 1)))\n",
    "    decoder.add(Conv2DTranspose(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    decoder.add(Conv2DTranspose(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    decoder.add(Conv2DTranspose(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    decoder.add(Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same'))\n",
    "    # decoder.add(Reshape(inp_shape))\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = stats_scaled.shape[1:]\n",
    "encoder_vae, decoder_vae = build_var_autoencoder(input_size, 256)\n",
    "\n",
    "inp = Input(input_size)\n",
    "code_vae = encoder_vae(inp)\n",
    "reconstruct = decoder_vae(code_vae)\n",
    "\n",
    "autoencoder_vae = Model(inp,reconstruct)\n",
    "autoencoder_vae.compile(optimizer='Adam', loss='KLDivergence')\n",
    "\n",
    "print(autoencoder_vae.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vae = autoencoder_vae.fit(stats_scaled, stats_scaled, batch_size = 0, epochs = 500, validation_split=0.1, callbacks = [], verbose = 0)\n",
    "\n",
    "plt.plot(history_vae.history['loss'])\n",
    "plt.plot(history_vae.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_vae = encoder_vae.predict(stats_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting VAE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot5clusters(encoded_data_vae[:,:3], label_sample, 'VAE (sample)', 'AE', sample_name)\n",
    "plot4clusters(encoded_data_vae[:,:3], label_bld_plt, 'VAE (build plate)', 'AE', bld_plt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 10)\n",
    "pca_transformed = pca.fit_transform(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot5clusters(pca_transformed[:,:3], label_sample, 'VAE (sample)', 'AE', sample_name)\n",
    "plot4clusters(pca_transformed[:,:3], label_bld_plt, 'VAE (build plate)', 'AE', bld_plt_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**homogeneity** Each cluster contains only members of a single class  \n",
    "\n",
    "**completeness** All members of a given class are assigned to the same cluster  \n",
    "\n",
    "**V-measure** Harmonic mean of homogeneity and completeness  \n",
    "\n",
    "$v = \\frac{(1+\\beta) \\times homogeneity \\times completeness}{\\beta \\times (homogeneity + completeness)}$\n",
    "\n",
    "**Rand Index** Similarity of the prediction with the ground truth  \n",
    "\n",
    "**Mutual Information** Function that measures the agreement of the predicted label with the ground truth\n",
    "\n",
    "**Silhouette Coefficient** If ground truth labels are not known, this coefficient relates to a model with better defined clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = label_sample \n",
    "titles = ['Linear AE', 'Non-Linear (sigmoid) AE', 'Non-Linear (relu)']\n",
    "for n_clusters_ in [2:4]:\n",
    "      estimators = [\n",
    "                    ('AE linear' , KMeans(n_clusters=n_clusters_), encoded_data_LE),\n",
    "                    ('AE Non-linear (sigmoid)' , KMeans(n_clusters=n_clusters_), encoded_data_sig),\n",
    "                    ('AE Non-linear (relu)' , KMeans(n_clusters=n_clusters_), encoded_data_rel)]\n",
    "\n",
    "      print('Number of clusters: %d' % n_clusters_)\n",
    "      for name, est, data in estimators:\n",
    "            X = data\n",
    "            est.fit(X)\n",
    "            labels = est.labels_\n",
    "            print(name,':')\n",
    "      #   print(labels[:]) \n",
    "            print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "            print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "            print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "            print(\"Adjusted Rand Index: %0.3f\"\n",
    "                  % metrics.adjusted_rand_score(labels_true, labels))\n",
    "            print(\"Adjusted Mutual Information: %0.3f\"\n",
    "                  % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "            print(\"Silhouette Coefficient: %0.3f\"\n",
    "                  % metrics.silhouette_score(X, labels))\n",
    "            print()\n",
    "      print()\n",
    "      print('----------------------------------------------------------------------------------')\n",
    "      print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = label_sample \n",
    "titles = ['PCA', 'Linear AE', 'Non-Linear (sigmoid) AE', 'Non-Linear (relu)']\n",
    "for n_clusters_ in [3]:\n",
    "      estimators = [('PCA'    , KMeans(n_clusters=n_clusters_), pca_transformed),\n",
    "                    ('AE linear' , KMeans(n_clusters=n_clusters_), encoded_data_LE),\n",
    "                    ('AE Non-linear (sigmoid)' , KMeans(n_clusters=n_clusters_), encoded_data_sig),\n",
    "                    ('AE Non-linear (relu)' , KMeans(n_clusters=n_clusters_), encoded_data_rel)]\n",
    "\n",
    "      print('Number of clusters: %d' % n_clusters_)\n",
    "      for name, est, data in estimators:\n",
    "            X = data\n",
    "            est.fit(X)\n",
    "            labels = est.labels_\n",
    "            print(name,':')\n",
    "      #   print(labels[:]) \n",
    "            print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "            print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "            print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "            print(\"Adjusted Rand Index: %0.3f\"\n",
    "                  % metrics.adjusted_rand_score(labels_true, labels))\n",
    "            print(\"Adjusted Mutual Information: %0.3f\"\n",
    "                  % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "            print(\"Silhouette Coefficient: %0.3f\"\n",
    "                  % metrics.silhouette_score(X, labels))\n",
    "            print()\n",
    "      print()\n",
    "      print('----------------------------------------------------------------------------------')\n",
    "      print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = label_sample \n",
    "titles = ['PCA', 'Linear AE', 'Non-Linear (sigmoid) AE', 'Non-Linear (relu)']\n",
    "for n_clusters_ in [3]:\n",
    "      estimators = [('PCA'    , KMeans(n_clusters=n_clusters_), pca_transformed),\n",
    "                    ('AE linear' , KMeans(n_clusters=n_clusters_), encoded_data_LE),\n",
    "                    ('AE Non-linear (sigmoid)' , KMeans(n_clusters=n_clusters_), encoded_data_sig),\n",
    "                    ('AE Non-linear (relu)' , KMeans(n_clusters=n_clusters_), encoded_data_rel)]\n",
    "\n",
    "    print('Number of clusters: %d' % n_clusters_)\n",
    "    for name, est, data in estimators:\n",
    "        X = data\n",
    "        est.fit(X)\n",
    "        labels = est.labels_\n",
    "        print(name,':')\n",
    "        print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "        print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "        print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "        print(\"Adjusted Rand Index: %0.3f\"\n",
    "                % metrics.adjusted_rand_score(labels_true, labels))\n",
    "        print(\"Adjusted Mutual Information: %0.3f\"\n",
    "                % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "        print(\"Silhouette Coefficient: %0.3f\"\n",
    "                % metrics.silhouette_score(X, labels))\n",
    "        print()\n",
    "    print()\n",
    "    print('----------------------------------------------------------------------------------')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
